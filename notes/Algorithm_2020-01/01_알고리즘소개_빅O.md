# 알고리즘 개요, 빅 O

강의영상1: [ALGO 01. Part 01. 알고리즘 소개, 빅O](https://youtu.be/Vge-4gBm1xM)

강의영상2: [ALGO 01. Part 02. 알고리즘 소개, 빅O](https://youtu.be/E7tImY7zvbw)

강의영상3: [ALGO 01. Part 03. 알고리즘 소개, 빅O](https://youtu.be/rKojDhl3vY0)

## 교육목표

- 알고리즘 소개
- 알고리즘 성능 분석
- 빅O
- 세부내용
  - 알고리즘 서술은 입력과 출력을 이용
  - 한 문제를 해결하는 알고리즘은 다양
    - 알고리즘을 분석할 수 있어야 한다.
    - 시간복잡도라는 성능 분석을 할 수 있어야 한다.
  - 시간복잡도, 공간복잡도 분석할 때 사용하는 기본 기법이 빅O
  - Karatsuba 알고리즘, merge sort 알고리즘

## 알고리즘 개요

- 홀로 어떤 목적(solving computational problem)을 위해 수행하는 일련의 단계
- 주어진 입력을 받아 요구되는 출력을 주는 일련의 단계
  - 문제는 몇 개의 매개변수를 가짐
    - n개의 수로 구성된 배열 A를 오름차순으로 정렬
      - 매개변수: 배열의 크기, 배열

### 알고리즘 특성

- 명확해야 한다.
- 정확해야 한다.
- 유한성(종결성) 특성을 가지고 있다.

### 문제의 서술

- 입력과 출력 제시
- 검색 문제
  - 입력: n개의 수로 구성된 배열 A와 찾고자 하는 수 x
  - 출력: x가 A에 있으면 yes 없으면 no를 출력

### 알고리즘의 서술

- 검색 문제에 대한 알고리즘
  - 일반적인 자연어 문장
    - 복잡한 알고리즘을 표현하기 어려움
    - 서술로부터 코드를 작성하는 것이 어려움
  - 의사코드를 사용
    - 언어와 독립

## 알고리즘의 성능

### 시간 복잡도

- 실제 시간을 측정할 수 있음
  - 프로그래밍 언어, 구현 방법, 컴퓨팅 환경 등에 영향을 받기 때문에 한계가 있다.
- 입력에 따라 필요한 기본 연산의 수를 계산
  - 기본 연산: 대입, 비교, 산술 연산 등
    - 더 이상 쪼개기 어려운 작은 단위의 연산
  - 간단한 사실: 알고리즘 성능은 반복문이 지배

### 공간 복잡도

- 알고리즘의 수행 시간만이 중요한 것은 아님
- 알고리즘을 수행하기 위해 사용되는 메모리의 크기도 중요
  - 특히 같은 시간 복잡도를 갖는 알고리즘이라면 공간 복잡도가 작은 알고리즘이 더 좋음

## 가장 많이 등장하는 수

- 입력: n개의 수로 구성된 배열
- 출력: 가장 많이 등장하는 수

> 의사 코드의 색인은 1부터

### 공간 vs 성능

```
M = -1
Mcount = 0
for i = 1 to n do
  V = A[i]
  count = 0
  for j = i to n do
    ifA[i] == V then count += 1;
  if Mcount < count then
    Mcount = count
    M = V
return M
```

- 연산이 n^2 만큼 필요함
- 공간 복잡도는 아래 것 보다 우수

```
count = []
for i = 1 to n
  count[A[i]] += 1
M =  1
for i = 2 to 100 do
  if count[M] < count[i] then M = i
return M
```

- 반복문이 중첩되어 있지는 않음
- 입력값이 1부터 100 사이의 수라는 것을 알고 있음
- 즉, 입력으로 들어오는 배열의 특성을 알고있을 때
- 연산이 n + 100 만큼 필요함
- 시간 복잡도가 위에 것 보다 우수

## 정수 곱셈

- 입력: 두 개의 n자리 정수 X, Y
- 출력: 두 수의 곱 X*Y

- 입력으로 들어오는 수를 제한하고 있음
  
- X, Y는 둘 다 같은 자릿수
  
- 시간복잡도 분석
- Y의 각 자리수 마다 n개의 곱셈이 필요함: n
  - 곱셈 과정에서 자리 올림으로 추가 덧셈 연산이 필요: n
    - => 총 필요 연산은 2n
    > 덧셈과 곱셈은 같은 비용의 연산은 아니지만 대략적인 분석을 할 때는 큰 문제가 되지 않음
  - 비용: <= 2n^2
- 결과를 합하는 과정: <= 2n^2의 덧셈
- 총 비용: <= 4n^2

## Algorithm Designer's Mantra

> Perhaps the most important principle for the good algorithm designer is to refuse to be content.
>
> - Aho, Hopcraft, Ullman, Analysis of Compter Algorithm, 1974

- Can we do better?

## 더 나은 정수 곱셈

- Karatsuba Algorithm

- 입력: 두 개의 n자리 정수 X, Y
- 출력: 두 수의 곱 X*Y

- X = 5678, Y = 1234
- a = 56, b = 78, c = 12, d = 34

1. ac = 672
2. bd = 2652
3. (a + b)(c + d) = 6164
4. (3) - (2) - (1) = 2840

## 재귀 알고리즘

- Karatsuba Algorithm은 대표적인 분할-정복 알고리즘
- 분할-정복 알고리즘은 재귀 알고리즘으로 구현하게 됨.
- X = 10^(n/2)a + b, Y = 10^(n/2)c + d
  - a,b,c,d: n/2 자리수
  - XY = 10^(n)ac + 10^(n/2)(ad + bc) + bd
  - ac,ad,bc,bd를 재귀적으로 구함
- Gauss's Trick: (a + b)(c + d) = ac + ad + bd + bd
  - ad + bc = (a + b)(c + d) - ac -  bd
  - 4개의 곱셈을 3개의 recursive multiplication만 필요하도록 줄일 수 있음 (추가적인 덧셈))

## 한 문제에 대한 다양한 알고리즘

- 한 문제를 해결하는 알고리즘은 다양함
- 중복 요소 존재 여부
  - 입력: n개의 수로 구성된 배열
  - 출력: 중복 요소가 있으면 true, 없으면 false

```
for i = 1 to n - 1 do
  for j = i + 1 to n do
    if A[i] == A[j] then return true;
return false;
```

- 최악의 경우로 분석: 가장 문제가 되었을 때
- n^2

```
sort A
for i = 2 to n do
  if A[i] == A[i-1] then return true;
return false;
```

- A를 정렬 > 같은 값은 인접해서 위치
- 비용: 정렬하는 비용 (가장 우수한 정렬 알고리즘: nlogn) + 비교 (n)
- n과 nlogn 정도되면 우수한 알고리즘
- nlogn은 비용에 대한 부담 없이 사용하면 된다.

```
S = empty set
for i = 1 to n do
  if A[i] in S then return true;
  else put A[i] in S
return false;
```

- 자료구조가 알고리즘의 성능을 결정하는 매우 중요한 요소가 된다.
- 집합 자료구조
  - 삽입 비용: O(1) / O(logn)
  - 찾는 비용: O(1) / O(logn)
- 전체 비용: O(n) / O(nlogn)

- 최악의 경우로 분석한 것이기 때문에 마지막 것이 항상 좋은게 아님
- 점근적인 분석이기 때문에 n의 값이 클 때 의미가 있음.

## 정렬 알고리즘

- 입력: n개의 수로 구성된 배열
- 출력: 같은 수로 구성된 오름차순으로 정렬된 배열
- 일반적 정렬 알고리즘은 이차 시간(quadratic time, n^2) 비용 필요
  - 삽입 정렬, 선택 정렬, 버블 정렬 등
- 빠른 정렬 알고리즘은 의사 선형 시한(quasilinear time, near linear time, nlogn) 비용 필요
  - 합병 정렬, 퀵 정렬, 힙 정렬 등

### 선택 정렬 (Selection Sort)

```
for i = 1 to n - 1 do
  minLoc = i
  for j = i + 1 to n do
    if A[minLoc] > A[j] then minLoc = j
  if minLoc != i then
    swap(A[minLoc], A[i])
```

- 최악과 최선이 같음
- n - 1 + n - 2 + ... + 1 = n(n - 1)/2
- 비교를 핵심 연산으로 생각해서 복잡도를 예상해보자.
- 배열이 어떻게 제시되든 동일한 복잡도를 가짐

### 삽입 정렬 (Insertion Sort)

```
for i = 2 to n do
  temp = A[i]
  j = i - 1
  while j >= 1 and temp < A[j] do
    A[j+1] = A[j]
    --j
  A[j+1] = temp
```

- 최악의 경우: 거꾸로 정렬되어 있는 경우
  - 1 + ... + n -2 + n - 1 = n(n - 1) / 2
- 최선의 경우: 이미 정렬되어 있는 경우
  - n - 1

### 버블 정렬 (Bubble Sort)

```
for i = 1 to n - 1 do
	flag = false
	for j = n to j = i + 1 do
		if A[j-1] > A[j] then
			swap(A[j-1], A[j])
			flag = true
		if not flag then break
```

- 최악의 경우: 거꾸로 정렬되어 있는 경우
  - n - 1 + n - 2 + ... + 1 = n(n - 1)/2
  - n - 1

### 합병 정렬

- 분학 정복 (divide-and-conquer) 방식의 알고리즘
  - 큰 문제를 똑같은 종류의 작은 문제로 쪼개서 해결
- 재귀 알고리즘
  - 단계 1. 재귀적으로 왼쪽 절반을 정렬
  - 단계 2. 재귀적으로 오른쪽 절반을 정렬
  - 단계 3. 두 반을 합병
- 재귀 알고리즘이므로 기저 사례에 대한 고려 필요 (재귀의 중단)
- 재귀 알고리즘의 시간 복잡도는 분석하기 어려움
  - 도사 정리를 배우면 간단
  - 보통 재귀호출이 얼마나 많이 이루어지는지 분석 해야 함
  - 비재귀 과정에서 일어나는 비용을 분석 해야 함
- merge (비재귀 과정)

```
L = 1
R = 1
for k = 1 to n do
	if A[L] < B[R] then
		C[k] = A[L]
		++L
	else
		C[k] = B[R]
		++R
(move remaining B or A to C)
```

- for 문 내에서 4개의 기본 연산이 소요
  - 크기가 n/2인 2개의 배열에 대한 merge 수행시간 <= 4n + 2 <= 6n
- 전체 비용 <= 6nlogn + 6n
  - 재귀트리의 깊이: logn + 1
    - 레벨 j: 2^j개의 재귀 호출이 이루어지고, 배열의 크기는 n/(2^j)
    - 레벨 j에서 연산 수: <= 2^j * 6 * (n/2^j) = 6n

### 검색

- 입력: n개의 수로 구성된 배열과 정수 v
- 출력: v가 배열에 있으면 그 위치, 없으면 -1

```
for i = 1 to n do
	if A[i] == v then return i
return -1
```

- 최선의 경우: 1
- 최악의 경우: n
- 평균 경우: (n+1)/2

#### 최악의 경우 분석을 선호하는 이유

- 분석하기 쉬움
- 많은 경우 편균 비용과 최악 비용이 같음
- 고객 반응 입장에서, 99번 빠르고 1번 느리면..?

## 알고리즘 분석

### 원리 1. 최악의 경우 분석

- 입력에 대한 어떤 가정도 필요 없는, 분석하기 상대적으로 쉬운 최악의 경우 분석이 더 효과적인 방법

### 원리 2. 큰 그림 분석

- 상수 계수와 낮은 차수 항들은 무시
  - 간단하다 (분석하기 쉬움)
  - 상수들은 프로그래밍 언어와 실행 환경 등에 의해 결정되는 요소
  - 이것들을 무시해도 예측 능력, 비교 능력이 유지된다.

### 원리 3. 점근적(asymptotic) 분석

- 입력 크기 n이 증가됨에 따라 알고리즘 수행시간의 증가 비율에 초점
  - 입력 크기가 작으면 시간 복잡도가 큰 의미가 없다.

#### 합병 정렬 vs 삽입 정렬

- n이 작으면 오히려 n^2이 nlogn보다 우수
- n이 클 경우에만 상수 계수와 낮은 차수 항들을 무시할 수 있다.

### 빠른 알고리즘이란

- 최악의 경우 수행시간이 입력 크기에 따라 느리게 증가하는 알고리즘
  - 증가 비율 (rate of growth)이 중요
  - 기준점은 선형 시간

### 알고리즘 종류

- 입력 크기가 같으면 입력과 상관 없이 항상 성능이 같은 경우
  - 정구 배열의 총합 계산, 선택 정렬
- 입력 크기가 같아도 입력에 따라 알고리즘 성능이 다른 경우
  - 비정렬 배열에서 선형 검색
  - 최악, 평균, 최선 비용 분석 가능

## 빅O

- 점근적 분석의 핵심
  - 상수 계수(constant factors)와 낮은 차수 항(low-order terms)들은 무시
    - 상수 계수: 시스템 의존적 요소
    - 낮은 차수: 큰 입력에 대해 의미가 없음
    - 합병정렬: 6nlogn + 6n -> O(nlogn)
  - 상수 계수, 낮은 차수 항들이 항상 무의미한 것은 아님
    - 같은 문제에 대한 알고리즘의 빅O가 같다면 의미가 있음
- 반복문의 형태를 잘 관찰할 필요가 있다.
- T(n) = O(f(n)) iff there exist positive constants c and n0 s.t. T(n) <= c*f(n) for all n >= n0.

### 알고리즘에서 n이란

- 고려되는 문제의 크기
  - 예) 리스트에 특정 요소 존재 여부: 리스트의 크기
  - 예) 주어진 양의 정수가 소수인지 판단: 정수 n을 표현하기 위한 비트 수

### Common Order

1. O(1): 상수시간(constant time) 비용
2. O(logn): 로스시간(logarithmic time) 비용, 한번에 처리해야 하는 양이 반씩 줄어드는 경우
3. O(n): 선형시간(linear time) 비용
4. O(nlogn): 의사선형시간(quasilinear time) 비용
5. O(n^2): 이창시간(quadratic time) 비용
6. 다항시간(polynomial time) 비용
7. O(2^n): 지수시간(exponential time) 비용
8. O(n!): 계승시간(factorial time) 비용

